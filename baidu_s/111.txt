

class DmozSpider(scrapy.Spider):
name = "dmoz"
allowed_domains = ["www.baidu.com"] 
# start_urls = ['http://www.baidu.com/s?q=&tn=baidulocal&ct=2097152&si=&ie=utf-8&cl=3&wd=seo%E5%9F%B9%E8%AE%AD']

start_urls = [] 
for word in open('/Users/sunjian/Desktop/tutorial/tutorial/spiders/word.txt'):
word = word.strip()
url = 'http://www.baidu.com/s?q=&tn=baidulocal&ct=2097152&si=&ie=utf-8&cl=3&wd=%s' % urllib.quote(word)
start_urls.append(url) 

def __get_url_query(self, url):
m = re.search("wd=(.*)", url).group(1) 
return m 


def parse(self,response):n = 0 for sel in response.xpath('//td[@class="f"]'):query = urllib.unquote(self.__get_url_query(response.url))item = DmozItem()title = re.sub('<[^>]*?>','',sel.xpath('.//a/font[@size="3"]').extract()[0])lading = sel.xpath('.//a[1]/@href').extract()[0]time = sel.xpath('.//font[@color="#008000"]/text()').re('(\d{4}-\d{1,2}-\d{1,2})')[0]size = sel.xpath('.//font[@color="#008000"]/text()').re('(\d+K)')[0]n += 1item['rank'] = nitem['title'] = title.encode('utf8')item['lading'] = lading.encode('utf8')item['time'] = time.encode('utf8')item['size'] = size.encode('utf8')item['query'] = query yield item

